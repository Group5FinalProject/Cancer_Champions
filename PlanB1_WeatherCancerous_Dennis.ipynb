{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8FvcmrtM8C2"
      },
      "source": [
        "# Is This Lungtumor Cancerous?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g025DtmpSAuD"
      },
      "source": [
        "This is a Plan B work in supporting Paln A (won't be presented if Plan A is successful).\n",
        "A dataset from https://www.kaggle.com/datasets/andrewmvd/lung-and-colon-cancer-histopathological-images was selected to train a regular CNN model.\n",
        "A patient interface was created at the end to tell weather a input lungtumor image indicates a cancer/carcinoma   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDlzMZguO4Le"
      },
      "source": [
        "Part 0: Importing Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "CrlPMjX16y_x"
      },
      "outputs": [],
      "source": [
        "# Cell(C) 1\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import requests\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0mLpQILVOwd_"
      },
      "source": [
        "Part 1: Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bkis9C4Q-uVe",
        "outputId": "0ed70a5a-d1c2-47a3-e2be-45654fffd19e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extraction successful.\n"
          ]
        }
      ],
      "source": [
        "# C2\n",
        "# Dennis Code Cell for loading in dataset lung_image_sets_22Aug2024 (reduced to 300 images)  to Google Colab\n",
        "\n",
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "#zip_file_path = '/content/sample_data/lung_image_sets_22Aug2024.zip'\n",
        "#zip_file_path = '/content/100lung_n.zip'\n",
        "zip_file_path = '/usr/lung_image_sets_22Aug2024.zip'\n",
        "#extract_folder = '/content/sample_data/lung_image_sets_22Aug2024'\n",
        "#extract_folder = '/content/100lung_n'\n",
        "extract_folder = '/usr/lung_image_sets_22Aug2024'\n",
        "\n",
        "# Create a ZipFile object\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    # Extract all the contents of zip file in the current directory\n",
        "    zip_ref.extractall(extract_folder)\n",
        "\n",
        "# Check if the extraction was successful\n",
        "if os.path.isdir(extract_folder):\n",
        "    print(\"Extraction successful.\")\n",
        "else:\n",
        "    print(\"Extraction failed.\")\n",
        "#After running this code, you should be able to access the contents of the lung_image_sets_new directory for further processing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeqEIUpKpyor",
        "outputId": "98bcec16-150c-4bac-9aa3-6264d9370bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 0 images.\n"
          ]
        }
      ],
      "source": [
        "# C3\n",
        "\n",
        "# ##### From Oliver 1\n",
        "\n",
        "# Load Images:\n",
        "# Path to the directory containing the images\n",
        "#image_directory = 'lung_image_sets/lung_aca'\n",
        "#image_directory = '/content/lung_aca'  #lung_aca1-1000.jpeg\n",
        "image_directory = extract_folder\n",
        "                #'/usr/lung_image_sets_22Aug2024/lung_image_sets_22Aug2024/lung_aca/lungaca1-100.jpeg\n",
        "                #'/usr/lung_image_sets_22Aug2024/lung_image_sets_22Aug2024/lung_n/lungn1-100.jpeg\n",
        "                #'/usr/lung_image_sets_22Aug2024/lung_image_sets_22Aug2024/lung_n/lungscc1-100.jpeg\n",
        "\n",
        "\n",
        "\n",
        "# List to store the loaded images\n",
        "images = []\n",
        "\n",
        "# Loop through all files in the directory\n",
        "for filename in os.listdir(image_directory):\n",
        "    if filename.endswith(\".jpeg\"):\n",
        "        # Construct the full path to the image file\n",
        "        image_path = os.path.join(image_directory, filename)\n",
        "\n",
        "        # Open the image and append it to the list\n",
        "        img = Image.open(image_path)\n",
        "        images.append(img)\n",
        "\n",
        "print(f\"Loaded {len(images)} images.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzf0ZA5IOnan"
      },
      "source": [
        "Part 2: preprocessing Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvVSZlDyretU",
        "outputId": "afbf587f-922b-4515-b9a1-217ed6fd5860"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing complete and data pickled.\n"
          ]
        }
      ],
      "source": [
        "# C4\n",
        "# ########## From Oliver 2\n",
        "\n",
        "# Size\n",
        "target_size = (256, 256)\n",
        "\n",
        "# List to store the preprocessed images\n",
        "preprocessed_images = []\n",
        "\n",
        "# List to store the preprocessed images\n",
        "preprocessed_images = []\n",
        "\n",
        "# Loop through the loaded images and preprocess them\n",
        "for img in images:\n",
        "    # Resize the image\n",
        "    img_resized = img.resize(target_size)\n",
        "\n",
        "    # Convert the image to grayscale (if we want to, unsure of the medical implications here)\n",
        "    # img_resized = img_resized.convert(\"L\")\n",
        "\n",
        "    # Convert the image to a NumPy array and normalize pixel values\n",
        "    img_array = np.array(img_resized) / 255.0\n",
        "\n",
        "    # Append the preprocessed image to the list\n",
        "    preprocessed_images.append(img_array)\n",
        "\n",
        "# Convert the list to a NumPy array for easier handling\n",
        "preprocessed_images = np.array(preprocessed_images)\n",
        "\n",
        "# Pickle the preprocessed images\n",
        "with open(\"preprocessed_images.pkl\", \"wb\") as f:\n",
        "    pickle.dump(preprocessed_images, f)\n",
        "\n",
        "print(\"Preprocessing complete and data pickled.\")\n",
        "\n",
        "###Preprocessing complete and data pickled."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SYU-Y2sSr_BN",
        "outputId": "faeeebf3-c2f4-407f-eca9-d52df134fc58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "JPEG\n",
            "(768, 768)\n",
            "RGB\n"
          ]
        }
      ],
      "source": [
        "# C5\n",
        "\n",
        "# Display information about the image\n",
        "print(img.format)\n",
        "print(img.size)\n",
        "print(img.mode)\n",
        "\n",
        "# Show the image\n",
        "img.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VAcm6TYzrfHl",
        "outputId": "38bf0def-5eae-4f5e-949d-2f725343dd6d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"filenames_df\",\n  \"rows\": 0,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "filenames_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-b44bc41e-7f78-478b-9034-f468fa3c5cb8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b44bc41e-7f78-478b-9034-f468fa3c5cb8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b44bc41e-7f78-478b-9034-f468fa3c5cb8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b44bc41e-7f78-478b-9034-f468fa3c5cb8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [0]\n",
              "Index: []"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# C6\n",
        "\n",
        "filenames_df = pd.DataFrame(preprocessed_images)\n",
        "#filenames_df = pd.read_csv(path)\n",
        "#filenames_df = pd.DataFrame(path)\n",
        "\n",
        "#filenames_df.head()\n",
        "#filenames_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5UjYg7sc7DnM"
      },
      "outputs": [],
      "source": [
        "# Print a random image from the list to ensure the import was successful\n",
        "#images[40]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oi4ehZw97KD6"
      },
      "outputs": [],
      "source": [
        "# Check the size of the second image\n",
        "#images[1].size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4v9dDSZPaQw"
      },
      "source": [
        "Part 3: Spliting Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qxpCTT987iof",
        "outputId": "2327f5e6-603d-4f61-d625-90921bd58d91"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"filenames_df\",\n  \"rows\": 0,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": null,\n        \"max\": null,\n        \"num_unique_values\": 0,\n        \"samples\": [],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "filenames_df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7615f054-464d-4248-91e2-0c7e3dc03375\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7615f054-464d-4248-91e2-0c7e3dc03375')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7615f054-464d-4248-91e2-0c7e3dc03375 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7615f054-464d-4248-91e2-0c7e3dc03375');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [0]\n",
              "Index: []"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# C7\n",
        "\n",
        "# Print the first few image filenames\n",
        "filenames_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTBfmCBP7mVJ"
      },
      "outputs": [],
      "source": [
        "# C8\n",
        "\n",
        "# First, remove the .png file extension, then split into two new columns to\n",
        "# differentiate between lungaca, lungn, lungscc by fectching the 4th letter of\n",
        "# the word of the image filename\n",
        "#filenames_df[['userid', 'pose', 'expression', 'eyes']] = filenames_df['files']\\\n",
        "#                                                            .str.replace('.png', '', regex=False)\\\n",
        "#                                                            .str.split('_', expand=True)\n",
        "filenames_df[['files', 'tumor_type']] = filenames_df['files']\\\n",
        "                                                            .str.replace('.jpeg', '', regex=False)\\\n",
        "                                                            .word.index[3], expand=True)\n",
        "filenames_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN5Cs1yG7s2D"
      },
      "outputs": [],
      "source": [
        "# C9\n",
        "\n",
        "# Now we can call our preprocessed pixel data 'X'\n",
        "X = normalized_images\n",
        "\n",
        "# For our purposes, we'll select the userid column as 'y'\n",
        "#y = filenames_df['userid']\n",
        "y = filenames_df['tumor_type']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IhwwRwS47t0D"
      },
      "outputs": [],
      "source": [
        "# C10\n",
        "\n",
        "# Check the total number of classes\n",
        "y.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuCgA3eS70at"
      },
      "outputs": [],
      "source": [
        "# C11\n",
        "\n",
        "# Convert values to numpy arrays\n",
        "X = np.array(X)\n",
        "y = np.array(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xX_VKFV771ga"
      },
      "outputs": [],
      "source": [
        "# C12\n",
        "\n",
        "# Now we'll split our data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4BohQ2TQVAw"
      },
      "source": [
        "Part 4: Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANS0CcNo781b"
      },
      "outputs": [],
      "source": [
        "# C13\n",
        "\n",
        "# Apply augmentation to the whole training dataset\n",
        "# Define the augmentation pipeline\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomRotation(0.2),         # Random rotation (20 degrees)\n",
        "    tf.keras.layers.RandomTranslation(0.1, 0.1), # Random horizontal and vertical shift\n",
        "    tf.keras.layers.RandomZoom(0.2),             # Random zoom\n",
        "    tf.keras.layers.RandomFlip('horizontal')     # Random horizontal flip\n",
        "])\n",
        "\n",
        "# Create variables to hold the X and y training data\n",
        "X_train_aug = []\n",
        "y_train_aug = []\n",
        "\n",
        "# Loop through all the images.\n",
        "for i in range(len(X_train)):\n",
        "    # Select the image\n",
        "    img = X_train[i]\n",
        "    # Select the label from the training data\n",
        "    label = y_train[i]\n",
        "\n",
        "    # Add a channel dimension for grayscale images\n",
        "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "\n",
        "    # Ensure that the input data has the correct shape\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Add 5 images for every original image\n",
        "    for j in range(5):\n",
        "        # Append a new image to the X list\n",
        "        X_train_aug.append(data_augmentation(img, training=True)[0].numpy())\n",
        "        # Append the label for the original image to the y list\n",
        "        y_train_aug.append(label)\n",
        "\n",
        "# Print the length of each list\n",
        "print(len(X_train_aug))\n",
        "print(len(y_train_aug))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BwPqVP6y8CdK"
      },
      "outputs": [],
      "source": [
        "# C14\n",
        "\n",
        "# Reshape test data for the model\n",
        "X_test_np = []\n",
        "for img in X_test:\n",
        "    # Add a channel dimension for grayscale images\n",
        "    img = np.expand_dims(img, axis=-1)  # Add channel dimension\n",
        "    # Append the image to the list\n",
        "    X_test_np.append(img)\n",
        "\n",
        "# Convert to numpy array\n",
        "X_test_np = np.array(X_test_np)\n",
        "\n",
        "# Check the shape of the first image\n",
        "X_test_np[0].shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TY4mXFNZQrFP"
      },
      "source": [
        "Part 5: Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_cixzLAk8Lp7"
      },
      "outputs": [],
      "source": [
        "# C15\n",
        "\n",
        "# One hot encode the y data\n",
        "y_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False).fit(np.array(y_train_aug).reshape(-1, 1))\n",
        "y_train_aug_enc = y_encoder.transform(np.array(y_train_aug).reshape(-1, 1))\n",
        "y_test_enc = y_encoder.transform(np.array(y_test).reshape(-1, 1))\n",
        "\n",
        "# Convert values to numpy arrays\n",
        "X_train_aug_np = np.array(X_train_aug)\n",
        "X_test_np = np.array(X_test_np)\n",
        "y_train_aug_np = np.array(y_train_aug_enc)\n",
        "y_test_np = np.array(y_test_enc)\n",
        "\n",
        "# Load and preprocess your CMU Face Images dataset (Ensure each image is labeled as \"with sunglasses\" or \"without sunglasses\")\n",
        "# The following code assumes that you have already loaded and preprocessed your dataset into 'X' and 'y' (features and labels).\n",
        "\n",
        "# Split the training dataset into training and validation sets\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train_aug_np, y_train_aug_np, test_size=0.2, random_state=42)\n",
        "\n",
        "# Print the total number of one_hot_encoded columns\n",
        "np.array(y_train).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qW7Ii4hk8QXM"
      },
      "outputs": [],
      "source": [
        "# C16\n",
        "\n",
        "# Define a CNN model\n",
        "model = keras.Sequential([\n",
        "    layers.Input((224, 224, 3)), #layers.Input((60, 64, 1)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(y_train.shape[1], activation='sigmoid')  # the nubmer of classes\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "batch_size = 32\n",
        "epochs = 10\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    validation_data=(X_val, y_val),\n",
        "    epochs=epochs\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azMKcKks8UQj"
      },
      "outputs": [],
      "source": [
        "# C17\n",
        "\n",
        "# Evaluate the model using the testing data\n",
        "model.evaluate(X_test_np, y_test_np)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1pvVuuxG06v"
      },
      "source": [
        "## **Patient Interface with Gradio - Image**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxtsfj8-IsGB"
      },
      "outputs": [],
      "source": [
        "# C18\n",
        "\n",
        "# Create a function called `sms_prediction` that takes in the SMS text and predicts the whether the text is \"not spam\" or \"spam\".\n",
        "# The function should return the SMS message, and say whether the text is \"not spam\" or \"spam\".\n",
        "def lungtumor_prediction(image):\n",
        "    \"\"\"\n",
        "    Predict the lung tumor classification of a given image using a pre-trained model.\n",
        "\n",
        "    Parameters:\n",
        "    - text (str): The image to be classified.\n",
        "\n",
        "    Returns:\n",
        "    - str: A message indicating whether the image is classified as benign or not.\n",
        "\n",
        "    This function takes a lung tumor image and a pre-trained pipeline model, then predicts the\n",
        "    tumor classification of the image. The result is a message stating whether the image is\n",
        "    classified as cancerous or not.\n",
        "    \"\"\"\n",
        "    # Create a variable that will hold the prediction of a new text.\n",
        "    # Call the sms_classification function with the DataFrame and set the result to the \"text_clf\" variable\n",
        "    text_clf = lungtumor_prediction(forilenames_df)\n",
        "\n",
        "    # Using a conditional if the prediction is \"ham\" return the message:\n",
        "    # f'The text message: \"{text}\", is not spam.' Else, return f'The text message: \"{text}\", is spam.'\n",
        "    print(f'The lungtumor: \"{image}\", is not cancerous.' if y = n, elif, f'The lungtumor: \"{image}\", is cancerous.', else, f'The lungtumor: \"{image}\", is cancerous.' if y = s )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFdYJY9QGv4P"
      },
      "outputs": [],
      "source": [
        "# C19\n",
        "\n",
        "# Create a Gradio interface\n",
        "!pip install gradio\n",
        "# Import Gradio\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdQQWNPmHEL4"
      },
      "outputs": [],
      "source": [
        "# C20\n",
        "\n",
        "# Create an instance of the Gradio Interface application function with the appropriate parameters.\n",
        "input_img = gr.inputs.Image(shape=(224, 224)) #input_img = gr.inputs.Image(shape=(150, 150))\n",
        "output = 'text' #target_img = gr.outputs.Image()\n",
        "app = gr.Interface(fn=text_clf, inputs=image, outputs=text, title='Is This Lung Tumor Cancerous?')\n",
        "# Launch the app\n",
        "app.launch()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
